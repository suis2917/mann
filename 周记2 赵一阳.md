觉得李沐的视频并不适合初学者，决定还是从机器学习基础开始学习

了解了llama3开源模型的使用，明白了可以通过投喂搜集的数据集来微调训练自己的大模型

学习了jupyter notebook的使用方便管理学习课程资料

学习了高等数学中有关方向导数以及梯度的知识点

以下是本周的机器学习课程笔记：

#### 爬虫

了解到爬虫是很多数据集的主要来源 学习了简单的爬虫库如BeautifulSoup  HTTP协议 状态码等 后续再深入学习

#### 	监督学习 ####

给算法一个数据集，回归和分类数据集，目的是拟合出正确答案（或01边界线）。

#### 	无监督学习

给算法一个数据集，但是不给数据集的正确答案，由算法自行分类数据集进入不同的集群。（聚类算法）

#### 单变量线性函数

**假设函数** hθ(x) = θ0 + θ1x
**代价函数** **平方误差函数**或者**平方误差代价函数** (最常用 类似最小二乘法)
![image-20240922151957963](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20240922151957963.png)

最小化代价函数，即minimize J(θ0, θ1)，得到的代价函数的 三维图如下

<img src="C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20240922130506222.png" alt="image-20240922130506222" style="zoom: 50%;" />

将**三维图平面化** 等高线图 contour plot
等高线的中心对应最小代价函数
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/7c87a5ada3a24143e7aaa5f70f6b1405.png)

#### 梯度下降算法

可用于尝试最小化任意函数的误差

**原理**：偏导表示的是**斜率**，斜率在最低点左边为负，最低点右边为正。 在移动过程中，偏导值会不断变小，进而移动的步幅也不断变小，最后不断收敛直到到达最低点；在最低点处偏导值为0，不再移动

了解原理后去做了一个课程配套的实验，成功线性拟合了一组数据集，具体实验笔记在ex1.pdf

![image-20240926195159607](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20240926195159607.png)

#### 特征归一化

用于数据预处理，使数据处在合理范围内，能使偏离值较为均匀的变化，使得梯度下降更便于找到最好值

![image-20240926213815164](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20240926213815164.png)

#### 逻辑回归

![image-20240927123549988](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20240927123549988.png)

#### 代价函数

逻辑回归的损失函数Loss  即期望若落空造成的损失

![image-20240926213916530](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20240926213916530.png)

**简化代价函数 **

![image-20240926214040272](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20240926214040272.png)

![image-20240926214058082](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20240926214058082.png)

这使得Loss也具有了碗的形状，使得逻辑回归也能使用梯度下降算法寻找极值



#### 逻辑回归模型

![img](https://i-blog.csdnimg.cn/blog_migrate/314f2f0da2c587794e6a53e4a2dcfdd2.png)



#### 简化代价函数与梯度下降

![img](https://i-blog.csdnimg.cn/blog_migrate/dd23a48ef34feb734b3d9c312c453335.png)

进而得到：

![img](https://i-blog.csdnimg.cn/blog_migrate/e2d4520a841c0c0e0cf74f97ee97d99d.png)

梯度下降：

![img](https://i-blog.csdnimg.cn/blog_migrate/4635508503b9ba2ea5b9ae3b2c9268e6.png)

**最后发现与正常的线性拟合公式相同**



#### 过拟合

当变量过多时，训练出来的假设能很好地拟合训练集，所以代价函数实际上可能非常接近于0，但得到的曲线为了千方百计的拟合数据集，导致它无法泛化到新的样本中，无法预测新样本数据（冗余项）



#### 正则化

正则化项：

![image-20241001120001255](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20241001120001255.png)

如果有很多参数，我们**不清楚哪个参数是高阶项**，即**不知道惩罚哪个能获得更好拟合的结果**，因此**引入正则化项统一惩罚参数**以得到较为简单的函数

正则化后：

![image-20241001165228169](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20241001165228169.png)

![image-20241001165329909](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20241001165329909.png)

得到最终公式



### 神经网络

输入前一层的激活，给定当前层的参数，它会输出下一层激活值 自定义sequential函数
中间层为网络层、隐藏层，最后输出为激活层

####　前向传播

![image-20241001203807159](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20241001203807159.png)
